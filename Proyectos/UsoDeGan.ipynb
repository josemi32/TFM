{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Aqui se explica el proceso para poder utilizar la red generativa entrenada en este proyecto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import random\n",
    "from PIL import Image,  ImageOps\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.layers import Input, Dense\n",
    "import time\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import Subset\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "import copy\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from torch.utils.data import RandomSampler, ConcatDataset\n",
    "import pandas as pd\n",
    "import shutil\n",
    "from PIL import ImageFile\n",
    "from tqdm import tqdm\n",
    "from PIL import ImageEnhance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construir el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando GPU: NVIDIA GeForce GTX 1060 6GB\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f\"Usando GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU no disponible, usando CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(Generator, self).__init__()\n",
    "        # Capas convolucionales\n",
    "        self.conv1 = self.conv_block(in_channels, 32, kernel_size=4, stride=2)  # k4n32s2\n",
    "        self.conv2 = self.conv_block(32, 64, kernel_size=4, stride=2)  # k4n64s2\n",
    "        self.conv3 = self.conv_block(64, 128, kernel_size=4, stride=2)  # k4n128s2\n",
    "        self.conv4 = self.conv_block(128, 256, kernel_size=4, stride=2)  # k4n256s2\n",
    "        self.conv5 = self.conv_block(256, 256, kernel_size=4, stride=2)  # k4n256s2\n",
    "\n",
    "        # Capas deconvolucionales con skip connections\n",
    "        self.deconv6 = self.deconv_block(256, 256, kernel_size=4, stride=2)  # k4n256s2k3n256s1\n",
    "        self.deconv7 = self.deconv_block(256*2, 128, kernel_size=4, stride=2)  # k4n128s2k3n128s1\n",
    "        self.deconv8 = self.deconv_block(128*2, 64, kernel_size=4, stride=2)  # k4n64s2k3n64s1\n",
    "        self.deconv9 = self.deconv_block(64*2, 32, kernel_size=4, stride=2)  # k4n32s2k3n32s1\n",
    "        self.deconv10 = self.deconv_block(32*2, 32, kernel_size=4, stride=2)  # k4n32s2k3n32s1k3n3s1\n",
    "        self.conv11 = nn.Conv2d(32, 3, 3, stride=1, padding=1, bias=False)\n",
    "    def conv_block(self, in_channels, out_channels, kernel_size, stride):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size, stride=stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "\n",
    "    def deconv_block(self, in_channels, out_channels, kernel_size, stride):\n",
    "        return nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=stride, padding=1, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv1_out = self.conv1(x)\n",
    "        conv2_out = self.conv2(conv1_out)\n",
    "        conv3_out = self.conv3(conv2_out)\n",
    "        conv4_out = self.conv4(conv3_out)\n",
    "        conv5_out = self.conv5(conv4_out)\n",
    "\n",
    "        deconv6_out = self.deconv6(conv5_out)\n",
    "        deconv7_out = self.deconv7(torch.cat((conv4_out, deconv6_out), 1))  # Skip connection\n",
    "        deconv8_out = self.deconv8(torch.cat((conv3_out, deconv7_out), 1))  # Skip connection\n",
    "        deconv9_out = self.deconv9(torch.cat((conv2_out, deconv8_out), 1))  # Skip connection\n",
    "        deconv10_out = self.deconv10(torch.cat((conv1_out, deconv9_out), 1))  # Skip connection\n",
    "        conv11_out = self.conv11(deconv10_out)\n",
    "        return torch.tanh(conv11_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cargar el peso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator = Generator(3,3).to(device)\n",
    "\n",
    "# Construir la ruta completa al archivo\n",
    "PATH =f'..\\Pesos\\L2 + Angular + Gradiente + Reentreno\\generator19.pth'\n",
    "\n",
    "# Cargar los pesos del modelo desde el archivo\n",
    "generator.load_state_dict(torch.load(PATH))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uso de la red generativa con una imagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256,256)), #El primer componente es la altura de la imagen y el segundo es su ancho\n",
    "    transforms.ToTensor() #Transforma las imagenes a tensor\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imagen de prueba guardada en ..\\ExperimentoUnaImagen\\Output\\imagen_generada.JPG\n"
     ]
    }
   ],
   "source": [
    "ruta_imagen_prueba = '../ImagenPrueba/Generador/Input/n01496331_18538.JPG' # Se pone la ruta de la imagen que se desee modificar\n",
    "\n",
    "# Cargar la imagen de prueba \n",
    "imagen_prueba = Image.open(ruta_imagen_prueba)\n",
    "imagen_prueba = transform(imagen_prueba).unsqueeze(0) \n",
    "imagen_prueba = imagen_prueba.to(device)\n",
    "with torch.no_grad():\n",
    "    generator.eval()  # Poner el generador en modo de evaluaci√≥n\n",
    "    imagen_generada = generator(imagen_prueba)\n",
    "nombre_archivo =f'..\\\\ExperimentoUnaImagen\\\\Output\\\\imagen_generada.JPG' #Guardar la imagen en la carpeta deseada, se recomienda que sea en ExperimentoUnaImagen \n",
    "torchvision.utils.save_image(imagen_generada, nombre_archivo)\n",
    "print(f'Imagen de prueba guardada en {nombre_archivo}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
