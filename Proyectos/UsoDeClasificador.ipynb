{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Aqui se explica el proceso para poder utilizar la red generativa entrenada en este proyecto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import random\n",
    "from PIL import Image,  ImageOps\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.layers import Input, Dense\n",
    "import time\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import Subset\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "import copy\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from torch.utils.data import RandomSampler, ConcatDataset\n",
    "import pandas as pd\n",
    "import shutil\n",
    "from PIL import ImageFile\n",
    "from tqdm import tqdm\n",
    "from PIL import ImageEnhance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construir el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando GPU: NVIDIA GeForce GTX 1060 6GB\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f\"Usando GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU no disponible, usando CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model2(num_classes):\n",
    "    #Los pesos si se entrenan\n",
    "    model_ft = models.inception_v3(weights=False) #Se carga el modelo inception_v3 sin sus pesos preentrenados.\n",
    "    # False en las redes convencionales, se entrenaran\n",
    "    set_parameter_requires_grad(model_ft, False)\n",
    "    # Se modifica la red auxiliar\n",
    "    num_ftrs = model_ft.AuxLogits.fc.in_features\n",
    "    model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "    #Se modifica la red principal para que sea de dos clases con una salida softmax y coger la con mas probabilidad.\n",
    "    model_ft.dropout= nn.Dropout(0.5)\n",
    "    num_ftrs = model_ft.fc.in_features\n",
    "    model_ft.fc = nn.Sequential(\n",
    "        nn.Linear(num_ftrs,num_classes),\n",
    "        nn.Dropout(0.3),\n",
    "        nn.Softmax(dim=1)\n",
    "    )\n",
    "\n",
    "    input_size=299 #Tamaño que usa la red\n",
    "    return model_ft,input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "Modeloft,_= initialize_model2(2)\n",
    "Modelo=Modeloft.to(device)\n",
    "\n",
    "#Para inutilizar la capa auxiliar.\n",
    "Modeloft.aux_logits=False"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "PATH = '..\\Pesos\\modeltranformaciones.pt'\n",
    "Modelo.load_state_dict(torch.load(PATH))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cargar el peso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = '..\\Pesos\\Discriminador\\mmodeltranformacionesEpocaBestEpoch.pt'\n",
    "Modelo.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uso de la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((299,299)), #El primer componente es la altura de la imagen y el segundo es su ancho\n",
    "    transforms.ToTensor() #Transforma las imagenes a tensor\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "ruta_imagen_prueba = '../ImagenPrueba/Discriminador/Input/im_f1000_.JPG' # Se pone la ruta de la imagen que se desee modificar\n",
    "\n",
    "# Cargar la imagen de prueba \n",
    "imagen_prueba = Image.open(ruta_imagen_prueba)\n",
    "imagen_prueba = transform(imagen_prueba).unsqueeze(0) \n",
    "imagen_prueba = imagen_prueba.to(device)\n",
    "with torch.no_grad():\n",
    "    Modelo.eval()  # Poner el generador en modo de evaluación\n",
    "    puntuacion = Modelo(imagen_prueba)[:, 1]\n",
    "\n",
    "print(f'Puntuacion imagen :{puntuacion.item()}')\n",
    "\n",
    "\n",
    "# Si es mayor a 0.5 es de mala calidad y si es inferior es de buena calidad."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
